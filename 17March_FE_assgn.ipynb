{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60660765-74c3-4106-9d60-90e4ee15d630",
   "metadata": {},
   "source": [
    "### Ques 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf074914-9355-48b9-9ad7-42d37988cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are missing values\n",
    "Missing values are those values that are not present in a dataset for a specific observation. \n",
    "There could be several reasons for missing values such as data corruption, data entry errors, and \n",
    "missing information.\n",
    "# Handling missing values\n",
    "Handling missing values is important because they can significantly affect the\n",
    "quality of data analysis and can lead to inaccurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08490d39-4059-4e69-9054-c636b38206ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance of handling missing values\n",
    "1-Missing data can cause bias in analysis and lead to false conclusions.\n",
    "\n",
    "2-Many statistical and machine learning algorithms cannot handle missing values and \n",
    "   may fail or produce incorrect results.\n",
    "\n",
    "3-Missing data can lead to reduced accuracy and predictive power of models.\n",
    "\n",
    "4-Ignoring missing values can lead to incomplete analysis and conclusions.\n",
    "\n",
    "5-Missing data can result in a loss of valuable information, which can adversely affect the performance\n",
    "  of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d44310-7032-4d5e-94b0-05911ae14f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-Some of the algorithms that are not affected by missing values are:\n",
    "\n",
    "2-Decision Trees: Decision Trees can handle missing values by splitting data based on available data points.\n",
    "\n",
    "3-Random Forest: Random Forest can handle missing values by averaging the missing values from the closest trees.\n",
    "\n",
    "4-K-Nearest Neighbors: K-Nearest Neighbors can handle missing values by replacing the missing value with\n",
    "  the average of the nearest neighbors.\n",
    "\n",
    "5-Naive Bayes: Naive Bayes can handle missing values by ignoring them and considering only the present features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c91d9a-f7cd-45a9-b37f-a9f29e706166",
   "metadata": {},
   "source": [
    "### Ques 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94cba9-1782-47a1-9f74-b0d230a65069",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are several techniques to handle missing data in a dataset\n",
    "1-Deletion\n",
    "2-Imputation\n",
    "3-Prediction\n",
    "\n",
    "# e.g. of each in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa73263-ecfc-40bd-b4a2-e2ace968b632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  5.0\n",
       "2  3.0  7.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1-Deletion\n",
    " \n",
    "import pandas as pd\n",
    " \n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, None], 'B': [5, None, 7, None, 9]})\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27697d6a-f729-47c9-8fdd-07c2e80d1bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  5.0\n",
       "1  2.0  7.0\n",
       "2  3.0  7.0\n",
       "3  4.0  7.0\n",
       "4  2.5  9.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2-Imputation\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, None], 'B': [5, None, 7, None, 9]})\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab16a2d9-45e5-4521-9b80-3e6d058c2c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B\n",
       "0  1.0  5.0\n",
       "1  2.0  5.0\n",
       "2  3.0  7.0\n",
       "3  4.0  5.0\n",
       "4  1.0  9.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.1 Mode Imputation\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, None], 'B': [5, None, 7, None, 9]})\n",
    "\n",
    "df.fillna(df.mode().iloc[0], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed1cd3-cb4c-4459-9ccb-81d32f02b5b0",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dcbf30-38eb-411b-b386-71db67e5edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imbalanced data is a situation where the classes in a classification problem have unequal or \n",
    "disproportionate class distribution.\n",
    "\n",
    "# e.g.\n",
    "Let’s assume that XYZ is a bank that issues a credit card to its customers. Now the bank is concerned that\n",
    "some fraudulent transactions are going on and when the bank checks their data they found that for each 2000\n",
    "transaction there are only 30 Nos of fraud recorded. So, the number of fraud per 100 transactions is less \n",
    "than 2%, or we can say more than 98% transaction is “No Fraud” in nature. Here, the class “No Fraud” is \n",
    "called the majority class, and the much smaller in size “Fraud” class is called the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02807ff2-3c7e-49a6-8ec3-7ba04c79d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if imbalanced data is not handled\n",
    "1-Bias in model Prediction\n",
    "2-Overfitting\n",
    "3-Poor Evalution\n",
    "4-Inaccurate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3cd18-e7d1-4596-8d88-f2d8c343aff7",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf7c19-b339-4edb-af88-ba3e4b803b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down sampling\n",
    "\n",
    "Down-sampling is a process of reducing the number of samples in the majority class to balance the \n",
    "class distribution. This can be useful when the majority class has significantly more samples than \n",
    "the minority class. One example of when down-sampling is required is in fraud detection. In fraud detection,\n",
    "there are often many more non-fraudulent transactions than fraudulent ones. In such cases, down-sampling can\n",
    "be used to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639a5c4-4b7a-4080-9604-4e22d5d50a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling\n",
    "\n",
    "Up-sampling is a process of increasing the number of samples in the minority class to balance the \n",
    "class distribution. This can be useful when the minority class has significantly fewer samples than \n",
    "the majority class. One example of when up-sampling is required is in medical diagnosis, where rare diseases have fewer samples than common ones.\n",
    "In such cases, up-sampling can be used to balance the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b7f2b-a94e-4976-88ee-b92e69c7f46a",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad460b8-787f-410d-b263-683399c82b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data argumentation\n",
    "Data augmentation is a technique used to increase the size of the training dataset by creating modified\n",
    "copies of existing data. It is commonly used in machine learning to reduce overfitting and improve the \n",
    "generalization of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea3771-a0a1-4b0c-be03-08f8d3672cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is smote\n",
    "SMOTE stands for Synthetic Minority Over-sampling Technique, and it is a type of data augmentation method\n",
    "that is used to address imbalanced datasets. \n",
    "It generates new synthetic samples of the minority class by interpolating between the feature vectors of\n",
    "neighboring minority class samples. This technique is particularly useful when the dataset has a class \n",
    "imbalance problem, where the number of samples in one class is much smaller than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b7ba5-d1b8-4732-bb98-8cca400e0ee2",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a94b15-949c-45b2-aaa0-089a4f9d91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers\n",
    "Outlier is an observation in a given dataset that lies far from the rest of the observations. \n",
    "That means an outlier is vastly larger or smaller than the remaining values in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f85d0-1847-4458-b6fd-2747a1accd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essential of handling outliers\n",
    "Handling outliers is essential for several reasons:\n",
    "1-Outliers can affect the statistical analysis of the data, such as the mean, standard deviation, \n",
    "and correlation coefficient, resulting in biased results.\n",
    "2-Outliers can also impact the distribution of the data, making it skewed and difficult to model accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae4cd6d-e078-42bd-bd51-10be2ad6694b",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45354c5c-e864-4db0-af72-14227c9604f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are several techniques that can be used to handle missing data in customer data analysis:\n",
    "1-Deletion: One of the simplest methods to handle missing data is to delete the entire row or column \n",
    "containing missing data. However, this method should be used with caution as it may lead to loss of valuable information.\n",
    "\n",
    "2-Imputation: Imputation involves filling in the missing values with a suitable estimate. \n",
    "The estimate can be based on the mean, median, mode or other statistical methods.\n",
    "\n",
    "3-Machine Learning-based imputation: This method involves using machine learning algorithms to predict \n",
    "the missing values. This technique can be used when there is a large amount of missing data.\n",
    "\n",
    "4-Multiple imputations: Multiple imputation is a method that involves creating several imputed datasets,\n",
    "each with a different imputed value for the missing data. These imputed datasets are then combined to obtain \n",
    "an estimate of the missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5d4c8-c7ca-4d2a-9687-b4b0c9859033",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa15a71-b684-431d-a3da-3bf25270ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are several strategies you can use to determine if missing data is missing at random or if there is \n",
    "a pattern to the missing data:\n",
    "1-Visual inspection: You can create plots or charts of the data to see if there are any visible patterns \n",
    "in the missing data.\n",
    "2-Correlation analyMachine learning algorithms: You can use machine learning algorithms to predict missing values based on other variables in the dataset.sis: You can calculate the correlation between the missing data and other variables in \n",
    "the dataset to determine if there is any relationship between them.\n",
    "3-Imputation methods: You can use imputation methods to fill in the missing data and compare the results\n",
    "with the original dataset to see if there are any significant differences.\n",
    "4-Machine learning algorithms: You can use machine learning algorithms to predict missing values based on\n",
    "    other variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce9cc97-8a33-41a8-a320-6b14d9398d5e",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0aa582-a340-414c-a63e-a1d1c732b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "When working with imbalanced datasets in machine learning, it is important to use appropriate evaluation\n",
    "metrics and techniques to accurately measure the performance of the model. \n",
    "Some strategies that can be used to evaluate the performance of a machine learning model on an imbalanced \n",
    "dataset are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f5964-ac2b-4193-a22c-68e845032fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-Resampling Techniques\n",
    "2-Evaluation Metrics\n",
    "3-Cost-Sensitive Learning\n",
    "4-Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0e9f6-948b-4b00-b094-6b5d41349bc9",
   "metadata": {},
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f23ef4-fb01-4bde-bad9-a7385ed9d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "To balance the dataset, the following methods can be employed to down-sample the majority class:\n",
    "\n",
    "1-Random Under-Sampling: In this method, instances from the majority class are randomly selected and removed \n",
    "from the dataset until the desired balance is achieved.\n",
    "\n",
    "2-Cluster-Based Under-Sampling: In this method, the majority class is clustered, and instances are selected\n",
    "for removal from each cluster until balance is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1926be37-0c72-4e7b-a888-2a42c13b0590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df = sns.load_dataset('tips')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "119b41ae-b575-4ab4-83e0-a7ab24483303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = df[df.total_bill=='total_bill']\n",
    "df_minority = df[df.tip=='tip']\n",
    "\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=False,    \n",
    "                                   n_samples=len(df_minority),     \n",
    "                                   random_state=42) \n",
    "\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "df_downsampled = df_downsampled.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5253034f-4e91-44ee-9ba2-4bbe6da62997",
   "metadata": {},
   "source": [
    "### Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494f350-06ea-4760-b75a-ec3be25e1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "When dealing with a dataset that has a low percentage of occurrences of a particular class, \n",
    "such as a rare event, there are several methods that can be used to balance the dataset and up-sample the \n",
    "minority class:\n",
    "\n",
    "1-Random Over-Sampling: In this method, the minority class is randomly duplicated until it has the same \n",
    "number of samples as the majority class.\n",
    "\n",
    "2-Synthetic Minority Over-Sampling Technique (SMOTE): This is a popular algorithm used to up-sample the\n",
    "minority class. In SMOTE, synthetic samples are generated by interpolating between minority class samples \n",
    "that are close to each other.\n",
    "\n",
    "3-Adaptive Synthetic Sampling (ADASYN): This method is similar to SMOTE, but it generates more synthetic \n",
    "samples for the minority class samples that are harder to learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
